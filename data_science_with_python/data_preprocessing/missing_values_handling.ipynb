{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Handling Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "row"
    ]
   },
   "source": [
    "There's some technique that used to handle missing values such as : \n",
    "\n",
    "| **Technique**                 | **Description**                                        | **When to Use**                                       | **Advantages**                                                              | **Disadvantages**                                                             | **Python Implementation**                                        | **Package**                    |\n",
    "|-------------------------------|-------------------------------------------------------|-------------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------------------|------------------------------------------------------------------|--------------------------------|\n",
    "| **Row Deletion**               | Deletes rows with missing values                      | When there are few missing values                     | Simple and easy to apply                                                   | Loss of important data/information if there are many missing values           | `data.dropna()`                                                  | **pandas**                     |\n",
    "| **Column Deletion**            | Deletes columns with many missing values              | When the column is irrelevant or has more than 50% missing | Simple, can improve efficiency                                              | Loss of important variables if applied carelessly                             | `data.drop(columns=['column'])`                                  | **pandas**                     |\n",
    "| **Mean/Median/Mode Imputation**| Replaces missing values with the mean, median, or mode | When data is numerical (mean/median) or categorical (mode) | Quick and simple                                                           | Ignores data variability, can introduce bias                                 | `SimpleImputer(strategy='mean')`                                 | **sklearn.impute**              |\n",
    "| **K-Nearest Neighbors (KNN)**  | Replaces missing values based on nearest neighbors    | When there is a complex relationship between variables | Considers relationships between variables                                  | Time-consuming and resource-heavy for large datasets                         | `KNNImputer(n_neighbors=5)`                                      | **sklearn.impute**              |\n",
    "| **Regression Imputation**      | Replaces missing values based on regression prediction| When variables are related                            | Considers deeper relationships between variables                            | More complex and requires assumptions about variable relationships            | Create your own regression model using `LinearRegression()`      | **sklearn.linear_model**        |\n",
    "| **Indicator for Missingness**  | Marks whether values are missing with a new variable  | When missing values themselves can be important       | Retains information from missing values                                     | Expands the dataset by adding extra columns                                 | `data['missing_indicator'] = data['column'].isnull().astype(int)`| **pandas**                     |\n",
    "| **Algorithm Ignore Missing**   | Algorithms that support missing values                | When using algorithms like Random Forest              | No need to perform imputation                                               | Not all algorithms support missing values                                    | RandomForest and XGBoost support missing values natively         | **sklearn.ensemble**, **xgboost**|\n",
    "| **Interpolation**              | Uses data patterns or trends to estimate missing values| For time series or sequential data                    | Uses existing data trends                                                   | Works only with sequential or time series data                               | `data['column'].interpolate(method='linear')`                   | **pandas**                     |\n",
    "| **Hot Deck Imputation**        | Replaces missing values with values from similar observations| In census or survey data                             | Considers similarity between observations                                  | Requires in-depth understanding of the data to identify similarities          | Not available in standard libraries, must be implemented manually | Manual implementation          |\n",
    "| **Multiple Imputation**        | Generates several imputation sets and combines them   | When there are many missing values and complex analysis | Considers uncertainty in the imputation                                     | Complex and requires more time and resources                                 | `IterativeImputer()`                                              | **sklearn.impute**, **statsmodels** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Packages and Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>some college</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>male</td>\n",
       "      <td>group D</td>\n",
       "      <td>high school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender race/ethnicity parental level of education lunch  \\\n",
       "6   female        group B                some college   NaN   \n",
       "41  female        group C          associate's degree   NaN   \n",
       "53    male        group D                 high school   NaN   \n",
       "70  female        group D                some college   NaN   \n",
       "95    male        group C          associate's degree   NaN   \n",
       "\n",
       "   test preparation course  math score  reading score  writing score  \n",
       "6                completed          88             95             92  \n",
       "41                    none          58             73             68  \n",
       "53                    none          88             78             75  \n",
       "70               completed          58             63             73  \n",
       "95               completed          78             81             82  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = pd.read_csv('/Users/Shared/Cloud Drive/repo_adi/dataset/Students_Performance_knn.csv')\n",
    "dataset.isna().sum()\n",
    "\n",
    "# accesing the NaN data on lunch Col\n",
    "dataset[dataset['lunch'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A. Row & Col Deletion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "lunch                          0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement Row Deletion\n",
    "row_del_dataset = dataset.dropna(axis=0) # with this function, we will drop the entire rows that null values exist in any columns\n",
    "print(row_del_dataset.isna().sum())\n",
    "\n",
    "# we can specify the targeted cols in order to evaluate the null values\n",
    "row_del_dataset_with_targeted_col = dataset.dropna(subset=['lunch'], axis=0)\n",
    "row_del_dataset_with_targeted_col.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# implement Col Deletion\n",
    "\n",
    "col_del_dataset = dataset.dropna(axis=1) # with this function, we will drop the entire cols that null values exist in any rows \n",
    "print(col_del_dataset.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **B. Mean/Median/Mode Imputation**\n",
    "\n",
    "When using imputation techniques with the scikit learn package, there are several strategies that can be used:\n",
    "\n",
    "1. mean,median, mode : used for numerical variable\n",
    "\n",
    "2. most_frequent : used for string variable\n",
    "\n",
    "3. constant : can be used for both numerical and string\n",
    "\n",
    "4. callable : custom imputation and also can be used for both numerical and string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use the central tendency imputation technique, we can use imputation model from scikit learn packages -> Simple\n",
    "\n",
    "# import packages\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# implement \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imputed_dataset = imputer.fit_transform(dataset)\n",
    "imputed_dataset = pd.DataFrame(data=imputed_dataset, columns=dataset.columns)\n",
    "\n",
    "imputed_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C. K Nearest Neighbors Imputation**\n",
    "\n",
    "* The KNNImputer in scikit-learn is generally used for numerical data, as it calculates missing values based on the distance between data points\n",
    "\n",
    "* If you're trying to use KNNImputer for categorical data, there are some steps that need to be taken because KNN works best with numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math score       0\n",
       "reading score    0\n",
       "writing score    0\n",
       "gender           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use knn imputer on numerical dataset\n",
    "# import packages\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# insntantiate dataset\n",
    "new_dataset = dataset.select_dtypes('number')\n",
    "new_dataset['gender'] = dataset['gender']\n",
    "new_dataset.loc[new_dataset['math score']<= 50, 'math score'] = np.nan\n",
    "\n",
    "# create the model\n",
    "knn_imputer = KNNImputer(n_neighbors=5, missing_values=np.nan)\n",
    "knn_imputed_dataset = knn_imputer.fit_transform(new_dataset.iloc[: ,:-1])\n",
    "\n",
    "knn_imputed_dataset = pd.DataFrame(data=knn_imputed_dataset, columns=new_dataset.columns[:-1])\n",
    "knn_imputed_dataset['gender'] = new_dataset['gender']\n",
    "knn_imputed_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **D Regression Imputation**\n",
    "\n",
    "* Regression Imputation is a method used to handle missing data by predicting missing values based on other observed variables in the dataset. In this technique, a regression model is built where the feature (or column) with missing data is the dependent variable, and the other features are independent variables (predictors). The regression model is then used to estimate and impute the missing values.\n",
    "\n",
    "* If a dataset has missing values in the column income, a regression model can be built using other features like age, education level, etc., to predict the missing values in income\n",
    "\n",
    "* If you're trying to use regression imputer for categorical data, there are some steps that need to be taken because regression works best with numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Steps to Use Regression Imputation:**\n",
    "\n",
    "1. Identify missing values in your dataset.\n",
    "\n",
    "2. Preprocess the data: Encode categorical features and split the dataset into observed (non-missing) and missing parts.\n",
    "\n",
    "3. Fit a regression model using the rows without missing values.\n",
    "\n",
    "4. Predict and impute missing values using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math score       0\n",
      "reading score    0\n",
      "writing score    0\n",
      "gender_male      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.602528</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   math score  reading score  writing score  gender_male  gender\n",
       "0   72.000000             72             74            0  female\n",
       "1   69.000000             90             88            0  female\n",
       "2   90.000000             95             93            0  female\n",
       "3   56.602528             57             44            1  female\n",
       "4   76.000000             78             75            1  female"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import relevant packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# 1. identify missing values\n",
    "new_dataset[new_dataset.isna().any(axis=1)].index# axis = 1 in order to evaluate the columns\n",
    "\n",
    "# 2 encode the dataset\n",
    "encoded_dataset = pd.get_dummies(data=new_dataset, columns=['gender'], drop_first=True, dtype=int) # 1 = male, 0 = female\n",
    "\n",
    "# 3. isolate the dataset as missing value dataset and non missing values dataset\n",
    "missing_values_dataset = encoded_dataset[encoded_dataset.isna().any(axis=1)]\n",
    "non_missing_values_dataset = encoded_dataset[~encoded_dataset.isna().any(axis=1)]\n",
    "\n",
    "# 4. prepare feature + response then construct regression model and train the model\n",
    "\n",
    "# 4.1 Prepare data for training (predictors and target)\n",
    "X = non_missing_values_dataset.drop(columns=['math score']) # features var\n",
    "y = non_missing_values_dataset['math score'] # response var\n",
    "\n",
    "# construct regression model and train the model\n",
    "regression_imputer = LinearRegression() \n",
    "regression_imputer.fit(X, y)\n",
    "\n",
    "# 5. Predict and Impute the Missing Values\n",
    "X_pred = missing_values_dataset.drop(columns=['math score'])\n",
    "y_pred = regression_imputer.predict(X_pred)\n",
    "\n",
    "# 5.1 Fill in the missing values in the original dataset\n",
    "encoded_dataset.loc[encoded_dataset['math score'].isna(),['math score']] = y_pred\n",
    "\n",
    "print (encoded_dataset.isna().sum())\n",
    "encoded_dataset['gender'] = np.where(encoded_dataset['math score'] == 1, 'male','female')# show the result\n",
    "encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this project doesn't cover some handling missing values technique such as : Hot Deck Imputation and Multiple Imputation.\n",
    "\n",
    "* we will cover those technique in the future :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
